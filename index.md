<div style="height:15px;"></div>
<p> I’m a Ph.D. student in the Interdisciplinary Program in Artificial Intelligence at Seoul National University, advised by <a href="https://vision.snu.ac.kr/gunhee/">Prof. Gunhee Kim</a> in the <a href="https://vision.snu.ac.kr/">Vision and Learning Lab</a>.</p>

<p>
  I’m interested in natural language processing and multimodal learning, with a long-term goal of developing autonomous AI agents that can collaboratively discover new knowledge alongside humans.
</p>

<p>
  I’m currently working on:

  * Large vision-language models
  * Multimodal retrieval-augmented generation (RAG)
  * Open-ended question answering.
</p>

<div style="height:15px;"></div>
---
<div style="height:15px;"></div>
### Education
<p style="margin:0">
  <div style="display:flex; justify-content:space-between">
    <a href="https://www.snu.ac.kr/">Seoul National University</a>
    <span> Mar 2024-Present</span>
  </div>
    <li style="margin-left: 12px;">Combined M.S. / Ph.D. of Interdisciplinary Program in Artificial Intelligence</li>
</p>

<p style="margin:0">
  <div style="display:flex; justify-content:space-between">
    <a href="https://www.korea.edu/sites/en/index.do">Korea University</a>
    <span> Mar 2018-Feb 2024</span>
  </div>
    <li style="margin-left: 12px;">B.S. in Computer Science and Engineering</li>
</p>

<div style="height:15px;"></div>
---
<div style="height:15px;"></div>
### Publication (* equal contribution)

<p style="margin:0">
  <div style="display:flex; justify-content:space-between">
  <a href="https://arxiv.org/abs/2511.12142">MAVIS: A Benchmark for Multimodal Source Attribution in Long-form Visual Question Answering</a>
  </div>
  <b>Seokwon Song</b>, Minsu Park, Gunhee Kim<br>
  AAAI 2026
</p>

<p style="margin:0">
  <div style="display:flex; justify-content:space-between">
  <a href="https://arxiv.org/abs/2502.06086">Is a Peeled Apple Still Red? Evaluating LLMs' Ability for Conceptual Combination with Property Type</a>
  </div>
  <b>Seokwon Song*</b>, Taehyun Lee*, Jaewoo Ahn, Jae Hyuk Sung, Gunhee Kim <br>
  NAACL 2025 (Oral)
</p>


<p style="margin:0">
  <div style="display:flex; justify-content:space-between">
  <a href="https://arxiv.org/abs/2308.14960">Read-only Prompt Optimization for Vision-Language Few-shot Learning</a>
  </div>
  Dongjun Lee*, <b>Seokwon Song*</b>, Jehee Suh, Junmyeong Choi, Sanghyeok Lee, Hyunwoo J. Kim<br>
  ICCV 2023
</p>
---
<div style="height:15px;"></div>
### Research Experience

<p style="margin:0">
  <div style="display:flex; justify-content:space-between">
  <a href="https://vision.snu.ac.kr/">
    Vision and Learning Lab, SNU</a>
    <span style>Oct 2023–Present</span>
  </div>
  Advised by Prof. Gunhee Kim
</p>

<p style="margin:0">
  <div style="display:flex; justify-content:space-between">
  <a href="https://www.lgresearch.ai/">
    Language Lab, LG AI Research</a>
    <span style>Jan 2023–Sep 2023</span>
  </div>
  Mentored by Hyunkyung Bae
</p>

<p style="margin:0">
  <div style="display:flex; justify-content:space-between">
  <a href="https://www.hyunwoojkim.com/">
    Machine Learning & Vision Lab, Korea University</a>
    <span style>May 2022–Dec 2022</span>
  </div>
  Advised by Prof. Hyunwoo J. Kim
</p>
<div style="height:15px;"></div>
---
<div style="height:15px;"></div>
### Work Experience
<p>
  <div style="display:flex; justify-content:space-between">
    <a href="https://www.lgresearch.ai/">LG AI Research</a>
    <span style>Jan 2023–Sep 2023</span>
  </div>
  Internship at Language Lab
</p>